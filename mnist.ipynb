{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 109065349.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 65514166.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 78265938.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 25000693.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Original  Random_1  Random_2  Random_3  Random_4  Random_5  Random_6  \\\n",
      "0         5         0         6         7         4         9         3   \n",
      "1         0         2         3         9         1         8         4   \n",
      "2         4         1         6         3         8         5         0   \n",
      "3         1         0         4         5         9         6         8   \n",
      "4         9         2         1         6         0         5         8   \n",
      "\n",
      "   Random_7  Random_8  Random_9  \n",
      "0         8         2         1  \n",
      "1         6         5         7  \n",
      "2         9         2         7  \n",
      "3         2         7         3  \n",
      "4         7         3         4  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-9375a0119e6f>:22: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  shuffled_labels = torch.tensor([np.random.choice(np.setdiff1d(range(10), [label.item()]), num_columns, replace=False) for label in labels])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load MNIST dataset using torchvision\n",
    "from torchvision import datasets, transforms\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_loader = torch.utils.data.DataLoader(dataset=mnist_dataset, batch_size=len(mnist_dataset))\n",
    "\n",
    "# Extract data and labels\n",
    "data, labels = next(iter(mnist_loader))\n",
    "data = data.view(len(mnist_dataset), -1)\n",
    "\n",
    "# Set the number of rows and columns\n",
    "num_rows = labels.size(0)\n",
    "num_columns = 9  # Assuming 9 additional random labels per row\n",
    "\n",
    "# Create a shuffled copy of the labels for each row\n",
    "shuffled_labels = torch.tensor([np.random.choice(np.setdiff1d(range(10), [label.item()]), num_columns, replace=False) for label in labels])\n",
    "\n",
    "# Combine the original labels and shuffled labels\n",
    "combined_labels = torch.cat((labels.view(-1, 1), shuffled_labels), dim=1)\n",
    "\n",
    "# Convert to NumPy array and create a DataFrame\n",
    "combined_labels_np = combined_labels.numpy()\n",
    "df = pd.DataFrame(combined_labels_np, columns=['Original'] + [f'Random_{i+1}' for i in range(num_columns)])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('mnist_labels_pytorch.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label                                    Flattened_Image\n",
      "0      5  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "1      0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "2      4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "3      1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "4      9  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Extract data and labels\n",
    "images = mnist_dataset.data.numpy()  # Convert PyTorch tensor to NumPy array\n",
    "labels = mnist_dataset.targets.numpy()\n",
    "\n",
    "# Reshape images to flatten them\n",
    "num_images, height, width = images.shape\n",
    "flattened_images = images.reshape(num_images, height * width)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Label': labels})\n",
    "df['Flattened_Image'] = flattened_images.tolist()  # Convert to list for DataFrame compatibility\n",
    "\n",
    "# Save to CSV file\n",
    "df.to_csv('mnist_data.csv', index=False)\n",
    "\n",
    "# Load data back from the CSV file\n",
    "loaded_df = pd.read_csv('mnist_data.csv')\n",
    "\n",
    "# Convert the 'Flattened_Image' column back to NumPy arrays\n",
    "loaded_df['Flattened_Image'] = loaded_df['Flattened_Image'].apply(eval)\n",
    "\n",
    "# Print the loaded DataFrame\n",
    "print(loaded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the first CSV file\n",
    "df1 = pd.read_csv('/home/aalmansour/source/lidc_slices/MNIST/mnist_data.csv')\n",
    "\n",
    "# Load the second CSV file\n",
    "df2 = pd.read_csv('/home/aalmansour/source/lidc_slices/MNIST/mnist_labels.csv')\n",
    "\n",
    "# Merge the two DataFrames based on a common column (e.g., 'common_column')\n",
    "merged_df = pd.merge(df1, df2, on='Label')\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('merged_mnist_file.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
